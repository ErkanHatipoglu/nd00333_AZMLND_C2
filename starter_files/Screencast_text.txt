Hi!

This is a screencast for project 2 of the 'Machine Learning Engineer with Microsoft Azure' Nanodegree program. A link to project files can be found in the description below.

We will use Azure to configure a cloud-based machine learning production model, deploy it, and consume it. We will also create, publish, and consume a pipeline.

We will use a local development environment along with a Microsoft Azure account for this project.

In this project, we are working with the Bank Marketing dataset. This dataset is about a phone call marketing campaign. A link to the original data can be found in the description below. The dataset can be used to predict if the client will subscribe to a term deposit or not. The target variable is y.

The first step is 'Authentication'. Authentication is crucial for the continuous flow of operations. We can use a service principal to allow authentication. I have already done this step and the details can be seen in the README file at my GitHub account. The properties of the service principal can be found on the Azure portal. You can see 'name', 'Application ID', and the 'Object ID' here.

The next step is the 'Automated ML Experiment'. In this step, we will create an experiment using Automated ML, configure a compute cluster, and use that cluster to run the experiment. I have already done the experiment as can be seen here. 

We can click on it to see the details. As can be seen, the best model is a voting ensemble with an accuracy of 92 percent. We can also see the related dataset by clicking on this link. This dataset is registered as 'Bankmartketing Dataset'

The third step is 'Deploying the Best Model' which is a voting ensemble for our case. This will allow us to interact with the HTTP API service and interact with the model by sending data over POST requests. We can see our deployed model by using the endpoints tab. This is our deployed model and we can see the details by clicking on it.

We can now enable Application Insights and retrieve logs. Application Insights is a special Azure service that provides key facts about an application. It is a very useful tool to detect anomalies and visualize performance. We can click on this link here for Application Insights. We can write and run the code (logs.py) to enable Application insights in our local machine.

Our next step is consuming the deployed model using Swagger. A swagger is a tool that helps build, document, and consume RESTful web services like the ones we are deploying in Azure ML Studio. Note that we need to download swagger.json to our local machine using the swagger URI and run both the serve.py and swagger.sh in the swagger folder.

We can use localhost to interact with the swagger instance running with the documentation for the HTTP API of the model. We can use this address to display the contents of the API for the model. The HTTP API methods and responses for the model are shown in the swagger UI.

We can now consume the deployed service via an HTTP API. To do this we need to modify both the 'scoring_uri' and the 'key' variables in the 'endpoint.py' file and execute it. It shows first yes then no answer as we are expecting.

We can use a benchmark to create a baseline or acceptable performance measure. To do that we need to run the benchmark.sh file.

We can also use a Jupyter Notebook to create and publish a Pipeline. Note that a compute instance should be running to run the Jupyter Notebook.

After we finish the notebook we can see the pipeline endpoints by using the pipelines or endpoints tab. We can also see our registered model by using the Models tab.

